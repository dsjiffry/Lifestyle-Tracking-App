{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Managing Lifestyle - Activity Tracking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr1Pvt0rtPmx"
      },
      "source": [
        "#Environment Details\n",
        "# !python --version\n",
        "# !nvidia-smi\n",
        "# !pip freeze\n",
        "\n",
        "#Use when not running in Colab\n",
        "# !pip install numpy==1.18.5\n",
        "# !pip install tensorflow==2.3.0\n",
        "# !pip install pandas==1.0.5\n",
        "# !pip install seaborn==0.10.1\n",
        "# !pip install matplotlib==3.2.2\n",
        "# !pip install sklearn==0.0\n",
        "# !pip install scipy==1.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gosKOT0NyDlI",
        "outputId": "c3b1f770-f0bd-4459-f802-40362ffba91e"
      },
      "source": [
        "#Pre-requisites\n",
        "!pip install gdown\n",
        "# !pip install tensorflow==2.3.0\n",
        "\n",
        "#Letâ€™s download the data\n",
        "# !gdown https://cdap-fmg.s3.us-east-2.amazonaws.com/WISDM_WATCH_ACCEL.txt\n",
        "!gdown https://drive.google.com/uc?id=1bol4ADpBa5G7GJ3ilUxbAiRLKUh-qm4g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA2CmEhVyGi9"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from pandas.plotting import register_matplotlib_converters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHPMdWWhRguJ"
      },
      "source": [
        "Reading the Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5Cok2nfXyITa",
        "outputId": "d2de1bf5-0631-4df2-b817-22a856b3a7a4"
      },
      "source": [
        "columnNames = ['user_id', 'activity', 'timestamp', 'x_axis', 'y_axis', 'z_axis']\n",
        "\n",
        "dataSet = pd.read_csv('WISDM_WATCH_ACCEL.txt', header=None, names=columnNames)\n",
        "dataSet.z_axis.replace(regex=True, inplace=True, to_replace=r';', value=r'')\n",
        "dataSet['z_axis'] = dataSet.z_axis.astype(np.float64)\n",
        "dataSet.dropna(axis=0, how='any', inplace=True)\n",
        "\n",
        "# removing the 'timestamp' column.\n",
        "dataSet.pop('timestamp')\n",
        "dataSet.head() #Outputs the first few lines of Data\n",
        "#dataSet.shape #Outputs number of rows and collumns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns-3Kk2ELRRd"
      },
      "source": [
        "spliting the data into training and test datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD8wnJ5ZyMJ1"
      },
      "source": [
        "dataSet_train = dataSet[dataSet['user_id'] <= 1640]\n",
        "dataSet_test = dataSet[dataSet['user_id'] > 1640]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VjeMEDHyT3M"
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "def create_dataset(X, y, time_steps=1, step=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(0, len(X) - time_steps, step):\n",
        "        v = X.iloc[i:(i + time_steps)].values\n",
        "        labels = y.iloc[i: i + time_steps]\n",
        "        Xs.append(v)        \n",
        "        ys.append(stats.mode(labels)[0][0])\n",
        "    return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
        "\n",
        "TIME_STEPS = 400\n",
        "STEP = 40\n",
        "\n",
        "# X_train is the training data set. \n",
        "# Y_train is the set of labels to all the data in x_train\n",
        "# x_test,y_test - This part of the data does not participate in the training of the model, but is used to evaluate the quality of the trained model.\n",
        "\n",
        "X_train, Y_train = create_dataset(\n",
        "    dataSet_train[['x_axis', 'y_axis', 'z_axis']], \n",
        "    dataSet_train.activity, \n",
        "    TIME_STEPS, \n",
        "    STEP\n",
        ")\n",
        "\n",
        "x_test, y_test = create_dataset(\n",
        "    dataSet_test[['x_axis', 'y_axis', 'z_axis']], \n",
        "    dataSet_test.activity, \n",
        "    TIME_STEPS, \n",
        "    STEP\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMPrRKQ1IRA4"
      },
      "source": [
        "Converting Activity names to numbers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_C6mv3wyVXT"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "\n",
        "enc = enc.fit(Y_train)\n",
        "\n",
        "Y_train = enc.transform(Y_train)\n",
        "y_test = enc.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPC0vmRYyXKA"
      },
      "source": [
        "# The model is defined as a Sequential Keras model.\n",
        "# with a LSTM layer. \n",
        "# Which is followed by a dropout layer intended to reduce overfitting of the model to the training data. \n",
        "# A dense layer is used to interpret the features extracted by the LSTM layer, \n",
        "# Final output layer is used to make predictions.\n",
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(\n",
        "      keras.layers.LSTM(\n",
        "          units=128, \n",
        "          input_shape=[X_train.shape[1], X_train.shape[2]]\n",
        "      )\n",
        ")\n",
        "model.add(keras.layers.Dropout(rate=0.5))  # 0 < rate < 1\n",
        "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
        "model.add(keras.layers.Dense(Y_train.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIntjAGTyZI-",
        "outputId": "2f63b187-c583-4016-803e-79ebafa8c6cb"
      },
      "source": [
        "# one epoch = one forward pass and one backward pass of all the training examples\n",
        "# batch size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n",
        "# number of iterations = number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=300,\n",
        "    batch_size=64,\n",
        "    validation_split=0.1,\n",
        "    shuffle=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KU52q5KybQP",
        "outputId": "cc2ca553-7efb-4063-b218-65130510393e"
      },
      "source": [
        "# See how well can it predict the test data, second number is accuracy percentage\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPp1ni9uR2Mf"
      },
      "source": [
        "Plotting the loss graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Nz43OkZt528g",
        "outputId": "de4b8ec6-dc15-4845-b642-c4d0f54a3e61"
      },
      "source": [
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='test loss')\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30S7wC3cRy04"
      },
      "source": [
        "Plotting the Confusion Matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "8qsMGENsydEt",
        "outputId": "19eb5a22-d464-4458-c75f-ac18bd7b8eef"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confMatrix(y_true, y_pred, class_names):\n",
        "  confMatrix = confusion_matrix(y_true, y_pred)\n",
        "  fig, ax = plt.subplots(figsize=(18, 16)) \n",
        "  ax = sns.heatmap(\n",
        "      confMatrix, \n",
        "      annot=True, \n",
        "      fmt=\"d\", \n",
        "      cmap=sns.diverging_palette(220, 20, n=7),\n",
        "      ax=ax\n",
        "  )\n",
        "\n",
        "  plt.ylabel('Actual')\n",
        "  plt.xlabel('Predicted')\n",
        "  ax.set_xticklabels(class_names)\n",
        "  ax.set_yticklabels(class_names)\n",
        "  b, t = plt.ylim() # discover the values for bottom and top\n",
        "  b += 0.5 # Add 0.5 to the bottom\n",
        "  t -= 0.5 # Subtract 0.5 from the top\n",
        "  plt.ylim(b, t) # update the ylim(bottom, top) values\n",
        "  plt.show() # ta-da!\n",
        "\n",
        "plot_confMatrix(\n",
        "  enc.inverse_transform(y_test),\n",
        "  enc.inverse_transform(y_pred),\n",
        "  enc.categories_[0]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxPfXa52RtdI"
      },
      "source": [
        "Creating the model h5 file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxBs9eV0Kv6C",
        "outputId": "1ee2e139-093f-44d5-8c5e-ba4ee6ee579b"
      },
      "source": [
        "# Exporting the model\n",
        "\n",
        "model.save(\"lifestyle_model.h5\")\n",
        "\n",
        "#reloading saved model\n",
        "new_model = tf.keras.models.load_model('lifestyle_model.h5')\n",
        "new_model.summary()\n",
        "\n",
        "print(\"\\nmain model result ///////////////////////////////////////////////////////\")\n",
        "model.evaluate(x_test, y_test) # main model result\n",
        "\n",
        "print(\"\\nsaved and loaded model result ///////////////////////////////////////////////////////\")\n",
        "new_model.evaluate(x_test, y_test) # saved and loaded model result"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}